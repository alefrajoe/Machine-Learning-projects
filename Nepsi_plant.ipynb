{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["8Xik53PKBHDZ"],"authorship_tag":"ABX9TyPa3lkKWJsKHt2IP5QDtRjb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Plant Disease Detection \n","Access: open, available at New Plant Disease Dataset \n","\n","Data Description \n","\n","The data records contain 54,309 images. The images span 14 crop species: Apple, Blueberry, Cherry, Corn, Grape, Orange, Peach, Bell Pepper, Potato, Raspberry, Soybean, Squash, Strawberry, Tomato. In containes images of 17 fungal diseases, 4 bacterial diseases, 2 mold (oomycete) diseases, 2 viral disease, and 1 disease caused by a mite. 12 crop species also have images of healthy leaves that are not visibly affected by a disease  \n","\n","Predictive task  \n","\n","The predictive task can change depending on the images selected: one can predict plant disease vs plant good health or plant type.  \n","\n","Related works:  \n","\n","[1] Schuler, Joao Paulo Schwarz, et al. \"Color-aware two-branch dcnn for efficient plant disease classification.\" MENDEL. Vol. 28. No. 1. 2022.  \n","\n","[2] Mohanty, Sharada P., David P. Hughes, and Marcel Salathé. \"Using deep learning for image-based plant disease detection.\" Frontiers in plant science 7 (2016): 1419."],"metadata":{"id":"8LwSS0ZESZmP"}},{"cell_type":"code","source":["!pip install opendatasets\n","\n","import opendatasets as od\n","od.download(\"https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset/download?datasetVersionNumber=2\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NDI0FYapTXzE","executionInfo":{"status":"ok","timestamp":1686118532752,"user_tz":-120,"elapsed":181399,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}},"outputId":"de18547c-98d7-478f-aff4-ef8a20f6355e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting opendatasets\n","  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.65.0)\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.13)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.3)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2022.12.7)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.27.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.26.15)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n","Installing collected packages: opendatasets\n","Successfully installed opendatasets-0.1.22\n","Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n","Your Kaggle username: guglielmotedeschi\n","Your Kaggle Key: ··········\n","Downloading new-plant-diseases-dataset.zip to ./new-plant-diseases-dataset\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2.70G/2.70G [00:32<00:00, 87.9MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"markdown","source":["\n","{\"username\":\"`guglielmotedeschi`\",\n","\n","\n","\"key\":\"`5306be7ca91268007d1f0059dbdb0b68`\"}"],"metadata":{"id":"ADrNPEt6L0mz"}},{"cell_type":"code","source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","# import warnings\n","import warnings\n","# filter warnings\n","warnings.filterwarnings('ignore')\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n","\n","import os\n","\n"],"metadata":{"id":"8rw0nrKBxJJ2","executionInfo":{"status":"ok","timestamp":1686118540004,"user_tz":-120,"elapsed":1633,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Import PyTorch\n","import torch\n","from torch import nn\n","\n","# Import torchvision \n","import torchvision\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","\n","# Import matplotlib for visualization\n","import matplotlib.pyplot as plt\n","\n","# Check versions\n","# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n","print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60Ty1syTpCG1","executionInfo":{"status":"ok","timestamp":1686118538382,"user_tz":-120,"elapsed":5651,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}},"outputId":"24e79591-6cbe-451a-cd2c-aa141c354037"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch version: 2.0.1+cu118\n","torchvision version: 0.15.2+cu118\n"]}]},{"cell_type":"code","source":["train_dir = \"/content/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\"\n","valid_dir = \"/content/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid\"\n","test_dir = \"/content/new-plant-diseases-dataset/test\"\n","diseases = os.listdir(train_dir)"],"metadata":{"id":"5av7rP9Zyofi","executionInfo":{"status":"ok","timestamp":1686118540006,"user_tz":-120,"elapsed":11,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["print(\"Total disease classes are: {}\".format(len(diseases)))\n","print(diseases)"],"metadata":{"id":"1pkZzAZlpcD0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686038880010,"user_tz":-120,"elapsed":17,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}},"outputId":"306ea9ea-0146-4a1c-f1cc-b41540ba7255"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total disease classes are: 38\n","['Blueberry___healthy', 'Raspberry___healthy', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Grape___healthy', 'Apple___Apple_scab', 'Orange___Haunglongbing_(Citrus_greening)', 'Potato___Early_blight', 'Cherry_(including_sour)___Powdery_mildew', 'Tomato___Early_blight', 'Potato___Late_blight', 'Corn_(maize)___Northern_Leaf_Blight', 'Apple___healthy', 'Peach___Bacterial_spot', 'Corn_(maize)___Common_rust_', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___Esca_(Black_Measles)', 'Strawberry___Leaf_scorch', 'Tomato___Target_Spot', 'Apple___Cedar_apple_rust', 'Pepper,_bell___Bacterial_spot', 'Tomato___Late_blight', 'Soybean___healthy', 'Strawberry___healthy', 'Peach___healthy', 'Tomato___Bacterial_spot', 'Pepper,_bell___healthy', 'Tomato___Leaf_Mold', 'Corn_(maize)___healthy', 'Apple___Black_rot', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Squash___Powdery_mildew', 'Tomato___Septoria_leaf_spot', 'Potato___healthy', 'Tomato___healthy', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Grape___Black_rot', 'Cherry_(including_sour)___healthy']\n"]}]},{"cell_type":"markdown","source":["#A look on Data\n"],"metadata":{"id":"8Xik53PKBHDZ"}},{"cell_type":"code","source":["plants = []\n","NumberOfDiseases = 0\n","for plant in diseases:\n","    if plant.split('___')[0] not in plants:\n","        plants.append(plant.split('___')[0])\n","    if plant.split('___')[1] != 'healthy':\n","        NumberOfDiseases += 1"],"metadata":{"id":"rjA8683t0F1U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Unique Plants are: \\n{plants}\")\n"],"metadata":{"id":"oueUYfSV0JSO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686037380561,"user_tz":-120,"elapsed":258,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}},"outputId":"b6e15e6c-88fd-4eb3-903a-d59b6dc5fc90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique Plants are: \n","['Tomato', 'Strawberry', 'Apple', 'Corn_(maize)', 'Potato', 'Orange', 'Blueberry', 'Soybean', 'Cherry_(including_sour)', 'Pepper,_bell', 'Peach', 'Raspberry', 'Squash', 'Grape']\n"]}]},{"cell_type":"code","source":["print(\"Number of plants: {}\".format(len(plants)))\n"],"metadata":{"id":"3fen6tCX0MuN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686037385161,"user_tz":-120,"elapsed":253,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}},"outputId":"36627dce-9d8f-40d4-dce7-28327c3c124d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of plants: 14\n"]}]},{"cell_type":"code","source":["print(\"Number of diseases: {}\".format(NumberOfDiseases))\n"],"metadata":{"id":"wTWrbOqR0OdB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686037386825,"user_tz":-120,"elapsed":340,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}},"outputId":"19154b47-8b8b-44fe-ba79-8ec8861ed032"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of diseases: 26\n"]}]},{"cell_type":"code","source":["nums = {}\n","for disease in diseases:\n","    nums[disease] = len(os.listdir(train_dir + '/' + disease))\n","    \n","# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n","\n","img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\n","img_per_class"],"metadata":{"id":"EUluzHRm0i-z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plotting number of images available for each disease\n","index = [n for n in range(38)]\n","plt.figure(figsize=(20, 5))\n","plt.bar(index, [n for n in nums.values()], width=0.3)\n","plt.xlabel('Plants/Diseases', fontsize=10)\n","plt.ylabel('No of images available', fontsize=10)\n","plt.xticks(index, diseases, fontsize=5, rotation=90)\n","plt.title('Images per each class of plant disease')"],"metadata":{"id":"6k2y8Vek0rV9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_train = 0\n","for value in nums.values():\n","    n_train += value\n","print(f\"There are {n_train} images for training\")"],"metadata":{"id":"745rC2LQ0zSF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686037408021,"user_tz":-120,"elapsed":253,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}},"outputId":"3d5e4842-d1ae-4bbb-8e9e-85995db7d9d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 70295 images for training\n"]}]},{"cell_type":"markdown","source":["#to Tensor\n"],"metadata":{"id":"lGw25CK74Hqg"}},{"cell_type":"code","source":["from torchvision.datasets import ImageFolder  # for working with classes and images\n","from torchvision import transforms\n","\n","transform = transforms.Compose([transforms.Resize(256),\n","                                    #transforms.CenterCrop(224),\n","                                    #transforms.RandomHorizontalFlip(),\n","                                    #transforms.RandomRotation(10),\n","                                    transforms.ToTensor()])\n","\n","\n","train = ImageFolder(train_dir, transform=transform) # ToTensor images come as PIL format, we want to turn into Torch tensors\n","valid = ImageFolder(valid_dir, transform=transform) \n","test = ImageFolder(test_dir, transform=transform)\n","\n","class_names= train.classes"],"metadata":{"id":"SzthgDmC4JwI","executionInfo":{"status":"ok","timestamp":1686118540441,"user_tz":-120,"elapsed":444,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["img, label = train[0]\n","print(img.shape, label)\n","print(\"n classes:\",len(class_names))"],"metadata":{"id":"mkGgcT3R4ats","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686047226540,"user_tz":-120,"elapsed":6,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}},"outputId":"92f4fa0e-a0da-48f7-954a-aceae5e7001d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 256, 256]) 0\n","n classes: 38\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","fig = plt.figure(figsize=(15, 9))\n","rows, cols = 4, 4\n","for i in range(1, rows * cols + 1):\n","    random_idx = torch.randint(0, len(train), size=[1]).item()\n","    img, label = train[random_idx]\n","    fig.add_subplot(rows, cols, i)\n","    plt.imshow(np.transpose(img.numpy(), (1, 2, 0)))\n","    plt.title(class_names[label])\n","    plt.axis(False);"],"metadata":{"id":"mx-_UBHVeGYr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Prepare a DataLoader"],"metadata":{"id":"uySBx-s3e2RV"}},{"cell_type":"markdown","source":["#nepsi to gpu\n"],"metadata":{"id":"h60_XFOWBZih"}},{"cell_type":"code","source":["# for moving data into GPU (if available)\n","def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available:\n","        return torch.device(\"cuda\")\n","    else:\n","        return torch.device(\"cpu\")\n","\n","# for moving data to device (CPU or GPU)\n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","# for loading in the device (GPU if available else CPU)\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl:\n","            yield to_device(b, self.device)\n","        \n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)"],"metadata":{"id":"R-n3k-JNqIj1","executionInfo":{"status":"ok","timestamp":1686118540443,"user_tz":-120,"elapsed":19,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["device = get_default_device()\n","device\n"],"metadata":{"id":"bCy3vFozqe93","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686118540444,"user_tz":-120,"elapsed":18,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}},"outputId":"f1daa78d-57c0-4af8-f81c-2d7c75ca9add"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from torch.utils.data import DataLoader # DataLoader permette di splittare il dataset in batches \n","\n","batch_size = 32\n","\n","train_dl = DataLoader(train, batch_size=batch_size, shuffle=True)\n","test_dl = DataLoader(test, batch_size=batch_size, shuffle=False)\n","valid_dl = DataLoader(valid, batch_size=batch_size, shuffle=True)\n","\n","train_dl = DeviceDataLoader(train_dl, device)\n","test_dl = DeviceDataLoader(test_dl, device)\n","valid_dl = DeviceDataLoader(valid_dl, device)\n","# Let's check out what we've created\n","print(f\"Dataloaders: {train_dl, test_dl}\") \n","print(f\"Length of train dataloader: {len(train_dl)} batches of {batch_size}\")\n","print(f\"Length of test dataloader: {len(test_dl)} batches of {batch_size}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h54AkCPI_0JF","executionInfo":{"status":"ok","timestamp":1686118540446,"user_tz":-120,"elapsed":17,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}},"outputId":"d93a983e-88ec-459d-a8ce-af227654b0ed"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataloaders: (<__main__.DeviceDataLoader object at 0x7fb4aec761d0>, <__main__.DeviceDataLoader object at 0x7fb5933e6e60>)\n","Length of train dataloader: 2197 batches of 32\n","Length of test dataloader: 2 batches of 32\n"]}]},{"cell_type":"markdown","source":["# Building the model\n"],"metadata":{"id":"qMYONfuO6qg4"}},{"cell_type":"markdown","source":["## CNN"],"metadata":{"id":"GT88xkGxOZcQ"}},{"cell_type":"code","source":["# convolution block with BatchNormalization\n","def NepsiBlock(in_channels, out_channels, pool=False):\n","    nepsi_layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","             nn.BatchNorm2d(out_channels),\n","             nn.ReLU(inplace=True)]\n","    if pool:\n","        nepsi_layers.append(nn.MaxPool2d(4))\n","    return nn.Sequential(*nepsi_layers)"],"metadata":{"id":"6u_Gj5xyOnTL","executionInfo":{"status":"ok","timestamp":1686119266518,"user_tz":-120,"elapsed":247,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class Plant(nn.Module):\n","    def __init__(self, in_channels: int, diseases: int):\n","        super().__init__()\n","\n","        self.conv1 = NepsiBlock(in_channels, 64)\n","        self.conv2 = NepsiBlock(64, 128, pool=True)\n","        self.res1 = nn.Sequential(NepsiBlock(128,128),NepsiBlock(128,128))\n","\n","        self.conv3 = NepsiBlock(128,256, pool=True)\n","        self.conv4 = NepsiBlock(256, 512, pool=True)\n","        self.res2 = nn.Sequential(NepsiBlock(512,512), NepsiBlock(512,512))\n","\n","        self.classifier = nn.Sequential((nn.MaxPool2d(4)),\n","                                        nn.Flatten(),\n","                                        nn.Linear(512, diseases))\n","        \n","\n","    def forward(self,x):\n","      out = self.conv1(x)\n","      out = self.conv2(out)\n","      out = self.res1(out) + out\n","      out = self.conv3(out)\n","      out = self.conv4(out)\n","      out = self.res2(out) + out\n","      out = self.classifier(out)\n","      return out\n","\n","torch.manual_seed(42)\n","#model = to_device(convo_nepsi(3, len(train.classes)), device) \n","\n","convo_nepsi = to_device (Plant(in_channels=3,\n","                               diseases=len(class_names)), device)\n","  \n","# Setup loss and optimizer\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params=convo_nepsi.parameters(), \n","                             lr=0.01)\n","\n","convo_nepsi"],"metadata":{"id":"hxtiHxk3AmsS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686119648954,"user_tz":-120,"elapsed":304,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}},"outputId":"9ea1ac42-2561-4842-b38b-1cd04898ad13"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Plant(\n","  (conv1): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (res1): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","    )\n","  )\n","  (conv3): Sequential(\n","    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv4): Sequential(\n","    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (res2): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n","    (1): Flatten(start_dim=1, end_dim=-1)\n","    (2): Linear(in_features=512, out_features=38, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["Function for Train"],"metadata":{"id":"6bx-fOGwkZdv"}},{"cell_type":"code","source":["def train_step(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer, accuracy_fn):\n","    \n","    model.train()\n","    train_loss, train_acc = 0, 0\n","    \n","    for batch, (X, y) in enumerate(data_loader):\n","        # 1. Forward pass\n","        y_pred = model(X)\n","        # 2. Calculate loss\n","        loss = loss_fn(y_pred, y)\n","        train_loss += loss.item()\n","        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n","        # 3. Optimizer zero grad\n","        optimizer.zero_grad()\n","        # 4. Loss backward\n","        loss.backward()\n","        # 5. Optimizer step\n","        optimizer.step()  \n","        \n","        if batch%100 == 0:\n","          print(batch)\n","          print(f'train loss {train_loss / (batch+1)}')\n","          print(f'train acc:{train_acc/ (batch+1)}')\n","          #print(y)\n","          #print(y_pred.argmax(dim=1))\n","          \n","    \n","    train_loss /= len(data_loader)\n","    train_acc /= len(data_loader)\n","    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n","\n","\n","\n","    # Calculate loss and accuracy per epoch and print out what's happening\n","      \n","def test_step(data_loader: torch.utils.data.DataLoader, model: torch.nn.Module, loss_fn: torch.nn.Module, accuracy_fn):\n","    model.eval() # put model in eval mode\n","    test_loss, test_acc = 0, 0\n","   \n","    # Turn on inference context manager\n","    with torch.no_grad(): \n","        for X, y in data_loader:\n","            # 1. Forward pass\n","            test_pred = model(X)\n","            # 2. Calculate loss and accuracy\n","            test_loss += loss_fn(test_pred, y).item()\n","            test_acc += accuracy_fn(y_true=y,\n","                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n","            )\n","            print(f'test loss {test_loss / (batch+1)}')\n","            print(f'test acc:{test_acc/ (batch+1)}')\n","          \n","        # Adjust metrics and print out\n","        test_loss /= len(data_loader)\n","        test_acc /= len(data_loader)\n","        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"],"metadata":{"id":"Ntfd7klYF8FO","executionInfo":{"status":"ok","timestamp":1686134402376,"user_tz":-120,"elapsed":444,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["from timeit import default_timer as timer \n","def print_train_time(start: float, end: float):\n","    \"\"\"Prints difference between start and end time.\n","\n","    Args:\n","        start (float): Start time of computation (preferred in timeit format). \n","        end (float): End time of computation.\n","        device ([type], optional): Device that compute is running on. Defaults to None.\n","\n","    Returns:\n","        float: time between start and end in seconds (higher is longer).\n","    \"\"\"\n","    total_time = end - start\n","    print(f\"Train time: {total_time:.3f} seconds\")\n","    return total_time\n","\n","def accuracy_fn(y_true, y_pred):\n","    \"\"\"Calculates accuracy between truth labels and predictions.\n","    Args:\n","        y_true (torch.Tensor): Truth labels for predictions.\n","        y_pred (torch.Tensor): Predictions to be compared to predictions.\n","    Returns:\n","        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n","    \"\"\"\n","    correct = torch.eq(y_true, y_pred).sum().item()\n","    acc = (correct / len(y_pred))\n","    return acc"],"metadata":{"id":"GYFl3ALJb7Ie","executionInfo":{"status":"ok","timestamp":1686134470461,"user_tz":-120,"elapsed":259,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["def eval_model(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, accuracy_fn):\n","    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\n","\n","    Args:\n","        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n","        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n","        loss_fn (torch.nn.Module): The loss function of model.\n","        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n","\n","    Returns:\n","        (dict): Results of model making predictions on data_loader.\n","    \"\"\"\n","    loss, acc = 0, 0\n","    model.eval()\n","    with torch.inference_mode():\n","        for X, y in data_loader:\n","            # Make predictions with the model\n","            y_pred = model(X)\n","            # Accumulate the loss and accuracy values per batch\n","            loss += loss_fn(y_pred, y)\n","            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)) # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n","        \n","        # Scale loss and acc to find the average loss/acc per batch\n","        loss /= len(data_loader)\n","        acc /= len(data_loader)\n","        \n","    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n","            \"model_loss\": loss.item(),\n","            \"model_acc\": acc}"],"metadata":{"id":"KYYySo_fADNb","executionInfo":{"status":"ok","timestamp":1686134471458,"user_tz":-120,"elapsed":1,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(42)\n","\n","# Measure time\n","from timeit import default_timer as timer\n","train_time_start = timer()\n","\n","epochs = 3\n","for epoch in range(epochs):\n","    print(f\"Epoch: {epoch}\\n---------\")\n","    train_step(data_loader=train_dl, \n","        model=convo_nepsi, \n","        loss_fn=loss_fn,\n","        optimizer=optimizer,\n","        accuracy_fn=accuracy_fn\n","    )\n","    test_step(data_loader=test_dl,\n","        model=convo_nepsi,\n","        loss_fn=loss_fn,\n","        accuracy_fn=accuracy_fn\n","    )\n","\n","train_time_end= timer()\n","total_train_time_model_1 = print_train_time(start=train_time_start, end=train_time_end)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7qh1TEED4sv","executionInfo":{"status":"ok","timestamp":1686137610880,"user_tz":-120,"elapsed":2984716,"user":{"displayName":"Guglielmo Tedeschi","userId":"12427337079834260043"}},"outputId":"c81f6c95-ef68-4826-8079-eab92d6b5a48"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0\n","---------\n","0\n","train loss 0.00012485039769671857\n","train acc:1.0\n","100\n","train loss 0.03295497166101018\n","train acc:0.9925742574257426\n","200\n","train loss 0.024546349054097305\n","train acc:0.9936256218905473\n","300\n","train loss 0.024479153044570302\n","train acc:0.9937707641196013\n","400\n","train loss 0.03292384998404004\n","train acc:0.9917394014962594\n","500\n","train loss 0.043447784144370914\n","train acc:0.9893962075848304\n","600\n","train loss 0.04910696868939998\n","train acc:0.9882487520798668\n","700\n","train loss 0.05100515313469908\n","train acc:0.9876069900142653\n","800\n","train loss 0.05394164078565603\n","train acc:0.9868133583021224\n","900\n","train loss 0.058543639144601894\n","train acc:0.9858837402885683\n","1000\n","train loss 0.058902142639584563\n","train acc:0.9855769230769231\n","1100\n","train loss 0.05832568935482776\n","train acc:0.9857799727520435\n","1200\n","train loss 0.05657707429223418\n","train acc:0.9861053288925895\n","1300\n","train loss 0.05828145386459941\n","train acc:0.9858762490392006\n","1400\n","train loss 0.05941415972363526\n","train acc:0.9855906495360457\n","1500\n","train loss 0.05982067650100013\n","train acc:0.9855512991339107\n","1600\n","train loss 0.060115318142274755\n","train acc:0.9855559025608994\n","1700\n","train loss 0.06041841753569153\n","train acc:0.9854497354497355\n","1800\n","train loss 0.06098694612679106\n","train acc:0.9854421154913937\n","1900\n","train loss 0.06104146059493496\n","train acc:0.9854024197790636\n","2000\n","train loss 0.061348014272166754\n","train acc:0.9853042228885557\n","2100\n","train loss 0.061959809505277554\n","train acc:0.9851856258924322\n","Train loss: 0.06107 | Train accuracy: 0.99%\n","Test loss: 51.99262 | Test accuracy: 0.05%\n","\n","Epoch: 1\n","---------\n","0\n","train loss 0.0154694439843297\n","train acc:1.0\n","100\n","train loss 0.05058766744668327\n","train acc:0.9873143564356436\n","200\n","train loss 0.051758014875092816\n","train acc:0.9877176616915423\n","300\n","train loss 0.04913550896322626\n","train acc:0.9885797342192691\n","400\n","train loss 0.04744968057304511\n","train acc:0.9884663341645885\n","500\n","train loss 0.04889195927641809\n","train acc:0.9874625748502994\n","600\n","train loss 0.054097836728321205\n","train acc:0.9868968386023295\n","700\n","train loss 0.05723662340031034\n","train acc:0.9861804564907275\n","800\n","train loss 0.060303525023037194\n","train acc:0.9856039325842697\n","900\n","train loss 0.06133813047762595\n","train acc:0.9850166481687015\n","1000\n","train loss 0.06080348336320339\n","train acc:0.9855144855144855\n","1100\n","train loss 0.058561087437723286\n","train acc:0.985950272479564\n","1200\n","train loss 0.05927850580697146\n","train acc:0.985793089092423\n","1300\n","train loss 0.05695939360689245\n","train acc:0.9861644888547272\n","1400\n","train loss 0.06000045045091225\n","train acc:0.9859698429693077\n","1500\n","train loss 0.06141487626485442\n","train acc:0.9856345769487008\n","1600\n","train loss 0.06128743961240427\n","train acc:0.9857315740162399\n","1700\n","train loss 0.06425402251568171\n","train acc:0.9851925338036449\n","1800\n","train loss 0.06324846644169248\n","train acc:0.9854247640199889\n","1900\n","train loss 0.06121736701898562\n","train acc:0.9858462651236192\n","2000\n","train loss 0.06002256357642259\n","train acc:0.9861006996501749\n","2100\n","train loss 0.05929709499760681\n","train acc:0.9862565445026178\n","Train loss: 0.05873 | Train accuracy: 0.99%\n","Test loss: 53.27209 | Test accuracy: 0.05%\n","\n","Epoch: 2\n","---------\n","0\n","train loss 0.0833592563867569\n","train acc:0.96875\n","100\n","train loss 0.04307901744800471\n","train acc:0.9885519801980198\n","200\n","train loss 0.05068338559969173\n","train acc:0.9878731343283582\n","300\n","train loss 0.057691131602005875\n","train acc:0.9869186046511628\n","400\n","train loss 0.05274945451612131\n","train acc:0.9879208229426434\n","500\n","train loss 0.05372534078840154\n","train acc:0.9878368263473054\n","600\n","train loss 0.05652764708196144\n","train acc:0.9871568219633944\n","700\n","train loss 0.05752483604604347\n","train acc:0.9868045649072753\n","800\n","train loss 0.055565313450581896\n","train acc:0.987203495630462\n","900\n","train loss 0.055478044238198625\n","train acc:0.9872710876803552\n","1000\n","train loss 0.054466623583884315\n","train acc:0.9874812687312687\n","1100\n","train loss 0.05421329913234605\n","train acc:0.9877668029064487\n","1200\n","train loss 0.055412519454775336\n","train acc:0.9876144879267277\n","1300\n","train loss 0.05539101523200638\n","train acc:0.9876056879323597\n","1400\n","train loss 0.05571799462695259\n","train acc:0.9876650606709493\n","1500\n","train loss 0.05618965206512917\n","train acc:0.9876957028647568\n","1600\n","train loss 0.055817165869214994\n","train acc:0.9875468457214241\n","1700\n","train loss 0.056241280617046766\n","train acc:0.9873787477954145\n","1800\n","train loss 0.05791184325066653\n","train acc:0.9871425596890616\n","1900\n","train loss 0.061960266703071996\n","train acc:0.98653669121515\n","2000\n","train loss 0.06173826572562421\n","train acc:0.986522363818091\n","2100\n","train loss 0.062070236903051884\n","train acc:0.9864647786768206\n","Train loss: 0.06228 | Train accuracy: 0.99%\n","Test loss: 72.50759 | Test accuracy: 0.03%\n","\n","Train time: 2984.607 seconds\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wKXGXBj9cWu6"},"execution_count":null,"outputs":[]}]}